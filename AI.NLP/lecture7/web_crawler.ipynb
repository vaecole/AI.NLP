{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Web Crawler\n",
    "- 给出一个种子URL\n",
    "- 对于一个URl对应的网页，获取该网页上的所有链接（a标签）列表，递归获取所有的URL（可以使用Redis存储和判重）\n",
    "- 下载有效网页的内容到本地\n",
    "- 对于给定的网页内容，爬取有效文本内容（有效文本筛选？）\n",
    "- URL递归获取可以采用DFS或者BFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Redis作为一个缓存服务，用来记录已经下载的网页（默认有效期90天），还可用来判断某个网页是否被下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis    # 导入redis模块，通过python操作redis 也可以直接在redis主机的服务端操作缓存数据库\n",
    "\n",
    "\n",
    "redis_pool = redis.ConnectionPool(host='127.0.0.1', port=6379, decode_responses=True) \n",
    "redis_url_visit_pre = 'url_visited:'\n",
    "\n",
    "def append_visited(url, filename):\n",
    "    if not filename:\n",
    "        return False\n",
    "    \n",
    "    redis_conn = redis.Redis(connection_pool = redis_pool)\n",
    "    key = redis_url_visit_pre + url\n",
    "    if not redis_conn.exists(key):\n",
    "        redis_conn.set(key, filename, ex = 90 * 24 * 60 * 60)\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_visited(url):\n",
    "    redis_conn = redis.Redis(connection_pool = redis_pool)\n",
    "    return redis_conn.exists(redis_url_visit_pre + url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 此方法访问一个URL，如果成功则获取对应网页的所有有效href，同时保存网页到本地并且更新缓存\n",
    "#### todo：还可以在此方法中增加对PageRank的支持，实现两个目的\n",
    "- 当前PageRank分数高的未下载页面优先访问\n",
    "- 爬取完毕后搜索算法需要用到PageRank\n",
    "- 但是本作业暂时不需要用PageRank，先不实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import requests\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import pathname2url\n",
    "import urllib.parse\n",
    "import logging\n",
    "\n",
    "\n",
    "def build_logger():\n",
    "    log_base = 'log'\n",
    "    if not os.path.exists(log_base):\n",
    "        os.mkdir(log_base)\n",
    "\n",
    "    if not os.path.exists(os.path.join(log_base,'error')):\n",
    "        os.mkdir(os.path.join(log_base,'error'))\n",
    "    logging.basicConfig(format='%(asctime)s %(message)s',\n",
    "                        filename='log/error/crawler0104.log', \n",
    "                        level = logging.ERROR,\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    if not os.path.exists(os.path.join(log_base,'warning')):\n",
    "        os.mkdir(os.path.join(log_base,'warning'))\n",
    "    logging.basicConfig(format='%(asctime)s %(message)s',\n",
    "                        filename='log/warning/crawler0104.log', \n",
    "                        level = logging.WARNING,\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "build_logger()\n",
    "\n",
    "def setup_custom_logger(name):\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                                  datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    handler = logging.FileHandler('.txt', mode='w')\n",
    "    handler.setFormatter(formatter)\n",
    "    screen_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    screen_handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(handler)\n",
    "    logger.addHandler(screen_handler)\n",
    "    return logger\n",
    "    \n",
    "\n",
    "\n",
    "def visit(url, limit_hostname = ''):\n",
    "    url_set = set()\n",
    "    \n",
    "    if is_visited(url):\n",
    "        return url_set\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(url) \n",
    "    except requests.ConnectionError:\n",
    "        print(\"Error: ConnectionError when request \"+ url)\n",
    "        return url_set\n",
    "    except Exception as e:\n",
    "        logging.warning('request error for ' + url + ', see error info.')\n",
    "        logging.error(str(e))\n",
    "        return url_set\n",
    "    \n",
    "    if not page.ok:\n",
    "        print(url + ' return ' + str(page.status_code))\n",
    "        return url_set\n",
    "    \n",
    "    parsed_uri = urlparse(url)\n",
    "    folder = urllib.parse.quote(parsed_uri.hostname, safe='')\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    filename = os.path.join(folder, urllib.parse.quote(url, safe=''))\n",
    "    \n",
    "    page_html = page.text\n",
    "    if not is_visited(url):\n",
    "        page_encode = page.encoding\n",
    "        try:\n",
    "            with open(filename,'w',encoding = page_encode) as file_write:\n",
    "                file_write.write(page_html)\n",
    "        except Exception as e:\n",
    "            logging.warning('writing file error for ' + url + ', see error info.')\n",
    "            logging.error(str(e))\n",
    "    \n",
    "    append_visited(url, filename)\n",
    "    \n",
    "    soup = BeautifulSoup(page_html)\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get(\"href\")\n",
    "        if href and href != '#' and href != './' and href != 'javascript:;' and 'http' in href and not is_visited(href):\n",
    "            if not limit_hostname or limit_hostname in href:\n",
    "                url_set.add(href)\n",
    "            \n",
    "    return url_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "def recurrent_visit(seed_url, limit_hostname = ''):\n",
    "    all_urls = set([seed_url])\n",
    "    count = 0\n",
    "    while all_urls:\n",
    "        print(len(all_urls))\n",
    "        clear_output(wait = True)\n",
    "\n",
    "        url = all_urls.pop()\n",
    "        next_urls = visit(url, limit_hostname, all_urls)\n",
    "        if next_urls:\n",
    "            all_urls.update(next_urls)\n",
    "            display(next_urls)\n",
    "        count += 1\n",
    "        if count >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'page' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4332bde3c8e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecurrent_visit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://www.cmiw.cn/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"cmiw\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-a42226ff4733>\u001b[0m in \u001b[0;36mrecurrent_visit\u001b[1;34m(seed_url, limit_hostname)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_urls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mnext_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnext_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mall_urls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-1afa05b5d1aa>\u001b[0m in \u001b[0;36mvisit\u001b[1;34m(url, limit_hostname)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' return '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0murl_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'page' referenced before assignment"
     ]
    }
   ],
   "source": [
    "recurrent_visit(\"http://www.cmiw.cn/\",\"cmiw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
